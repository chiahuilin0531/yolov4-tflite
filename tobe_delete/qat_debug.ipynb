{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 19:48:43.643599: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/user/anaconda3/envs/WJtf29/lib/python3.8/site-packages/tensorflow/lite/python/interpreter is not end with tflite_runtime/interpreter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "from tqdm import tqdm\n",
    "FLAGS = edict()\n",
    "\n",
    "# FLAGS.weights ='./checkpoints/day_tw_qat_tf23/save_model_final_tflite/'\n",
    "FLAGS.weights ='./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/'\n",
    "FLAGS.output ='./checkpoints/tmp.tflite'\n",
    "FLAGS.input_size =608\n",
    "FLAGS.quantize_mode ='float32'\n",
    "FLAGS.dataset =\"datasets/data_selection_mix/anno/val_3cls.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "  len_img=50\n",
    "  fimage = open(FLAGS.dataset).readlines()\n",
    "  fimage = [line.split()[0] for line in fimage]\n",
    "  np.random.seed(0)\n",
    "  np.random.shuffle(fimage)\n",
    "  with tqdm(total=len_img, ncols=200) as pbar:\n",
    "    for input_value in range(len_img):\n",
    "      if os.path.exists(fimage[input_value]):\n",
    "        original_image=cv2.imread(fimage[input_value])\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        # Processing V1\n",
    "        # image_data = utils.image_preprocess(np.copy(original_image), [FLAGS.input_size, FLAGS.input_size])\n",
    "        #####################################################################################################\n",
    "        # Processing V2\n",
    "        image_data = cv2.resize(np.copy(original_image), (FLAGS.input_size, FLAGS.input_size))\n",
    "        image_data = image_data / 255.0\n",
    "        #####################################################################################################\n",
    "        img_in = image_data[np.newaxis, ...].astype(np.float32)\n",
    "        pbar.set_postfix({\n",
    "          'image': fimage[input_value]\n",
    "        })\n",
    "        pbar.update(1)\n",
    "        yield [img_in]\n",
    "      else:\n",
    "        pbar.set_postfix({\n",
    "          'image': ''\n",
    "        })\n",
    "        pbar.update(1)\n",
    "\n",
    "def add_statistic(filename):\n",
    "  layer_stats = pd.read_csv(filename)\n",
    "  print(layer_stats.head())\n",
    "  layer_stats['range'] = 255.0 * layer_stats['scale']\n",
    "  layer_stats['rmse/scale'] = layer_stats.apply(\n",
    "      lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
    "  return layer_stats\n",
    "  # layer_stats[['op_name', 'range', 'rmse/scale']].head()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 19:51:15.889299: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-06-27 19:51:15.889345: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-06-27 19:51:15.889527: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-27 19:51:15.928767: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2022-06-27 19:51:15.928819: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-27 19:51:16.059778: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-06-27 19:51:16.540086: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-27 19:51:16.750453: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 860927 microseconds.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:41<00:00,  1.19it/s, image=datasets/data_selection/images/image_000741.jpg]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:05<00:00,  1.31s/it, image=datasets/data_selection/images/image_000741.jpg]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin model 6011416 bytes\n",
      "   op_name  tensor_idx  num_elements    stddev  mean_error  max_abs_error  \\\n",
      "0     RELU         118     2957312.0  0.006270   -0.002940       0.122591   \n",
      "1      PAD         122     2976800.0  0.000000    0.000000       0.000000   \n",
      "2  CONV_2D         126     1478656.0  0.173421    0.000573       0.929668   \n",
      "3     RELU         130     1478656.0  0.048481    0.006388       0.131863   \n",
      "4  CONV_2D         134     1478656.0  0.110942    0.000437       0.963905   \n",
      "\n",
      "   mean_squared_error     scale  zero_point  \\\n",
      "0            0.000050  0.247125        -128   \n",
      "1            0.000000  0.247125        -128   \n",
      "2            0.030075  0.600441          14   \n",
      "3            0.002393  0.266078        -128   \n",
      "4            0.012308  0.384223          27   \n",
      "\n",
      "                                         tensor_name  \n",
      "0                              model/tf.nn.relu/Relu  \n",
      "1                   model/quant_zero_padding2d_1/Pad  \n",
      "2  model/quant_batch_normalization_1/FusedBatchNo...  \n",
      "3                            model/tf.nn.relu_1/Relu  \n",
      "4  model/quant_batch_normalization_2/FusedBatchNo...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(os.path.dirname(FLAGS.output)):\n",
    "  os.makedirs(os.path.dirname(FLAGS.output))\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FLAGS.weights)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.allow_custom_ops = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "  converter=converter, debug_dataset=representative_data_gen)\n",
    "debugger.run()\n",
    "\n",
    "\n",
    "origin_int8_model = debugger.get_nondebug_quantized_model()\n",
    "num_of_bytes = open('./origin_int8_model.tflite', 'wb').write(origin_int8_model)\n",
    "print(f'origin model {num_of_bytes} bytes')\n",
    "\n",
    "RESULTS_FILE = './debugger_results.csv'\n",
    "RESULTS_FILE_V2 = './debugger_results_V2.csv'\n",
    "with open(RESULTS_FILE, 'w') as f:\n",
    "  debugger.layer_statistics_dump(f)\n",
    "layer_stats = add_statistic(RESULTS_FILE)\n",
    "layer_stats.to_csv(RESULTS_FILE_V2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.bar(np.arange(len(layer_stats)), layer_stats['range'])\n",
    "ax1.set_ylabel('range')\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(len(layer_stats)), layer_stats['rmse/scale'])\n",
    "ax2.set_ylabel('rmse/scale')\n",
    "plt.savefig('int8_analysis.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold=0.28 #0.295 # 1./np.sqrt(12) + 0.0001 # 0.30\n",
    "# print(threshold)\n",
    "# layer_stats[layer_stats['rmse/scale'] > threshold][[\n",
    "#     'op_name', 'range', 'rmse/scale', 'tensor_name', 'mean_squared_error', 'scale', 'num_elements'\n",
    "# ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of freeze layer 65/97\n",
      "['model/tf.nn.relu/Relu'\n",
      " 'model/quant_batch_normalization_1/FusedBatchNormV3;model/quant_conv2d_8/Conv2D;model/quant_conv2d_1/Conv2D'\n",
      " 'model/tf.nn.relu_1/Relu'\n",
      " 'model/quant_batch_normalization_2/FusedBatchNormV3;model/quant_conv2d_8/Conv2D;model/quant_conv2d_2/Conv2D'\n",
      " 'model/tf.nn.relu_2/Relu'\n",
      " 'model/quant_batch_normalization_3/FusedBatchNormV3;model/quant_conv2d_4/Conv2D;model/quant_conv2d_3/Conv2D'\n",
      " 'model/tf.nn.relu_3/Relu'\n",
      " 'model/quant_batch_normalization_4/FusedBatchNormV3;model/quant_conv2d_4/Conv2D'\n",
      " 'model/tf.nn.relu_4/Relu'\n",
      " 'model/quant_batch_normalization_5/FusedBatchNormV3;model/quant_conv2d_8/Conv2D;model/quant_conv2d_5/Conv2D'\n",
      " 'model/tf.nn.relu_5/Relu'\n",
      " 'model/quant_batch_normalization_6/FusedBatchNormV3;model/quant_conv2d_12/Conv2D;model/quant_conv2d_6/Conv2D'\n",
      " 'model/tf.nn.relu_6/Relu'\n",
      " 'model/quant_batch_normalization_7/FusedBatchNormV3;model/quant_conv2d_8/Conv2D;model/quant_conv2d_7/Conv2D'\n",
      " 'model/tf.nn.relu_7/Relu'\n",
      " 'model/quant_batch_normalization_8/FusedBatchNormV3;model/quant_conv2d_8/Conv2D'\n",
      " 'model/tf.nn.relu_8/Relu'\n",
      " 'model/quant_batch_normalization_9/FusedBatchNormV3;model/quant_conv2d_12/Conv2D;model/quant_conv2d_9/Conv2D'\n",
      " 'model/tf.nn.relu_9/Relu'\n",
      " 'model/quant_batch_normalization_10/FusedBatchNormV3;model/quant_conv2d_15/Conv2D;model/quant_conv2d_10/Conv2D'\n",
      " 'model/tf.nn.relu_10/Relu'\n",
      " 'model/quant_batch_normalization_11/FusedBatchNormV3;model/quant_conv2d_12/Conv2D;model/quant_conv2d_11/Conv2D'\n",
      " 'model/tf.nn.relu_11/Relu'\n",
      " 'model/quant_batch_normalization_12/FusedBatchNormV3;model/quant_conv2d_12/Conv2D'\n",
      " 'model/tf.nn.relu_12/Relu'\n",
      " 'model/quant_batch_normalization_13/FusedBatchNormV3;model/quant_conv2d_15/Conv2D;model/quant_conv2d_13/Conv2D'\n",
      " 'model/tf.nn.relu_13/Relu'\n",
      " 'model/quant_batch_normalization_14/FusedBatchNormV3;model/quant_conv2d_16/Conv2D;model/quant_conv2d_14/Conv2D'\n",
      " 'model/tf.nn.relu_14/Relu'\n",
      " 'model/quant_batch_normalization_15/FusedBatchNormV3;model/quant_conv2d_15/Conv2D'\n",
      " 'model/tf.nn.relu_15/Relu'\n",
      " 'model/quant_batch_normalization_16/FusedBatchNormV3;model/quant_conv2d_16/Conv2D'\n",
      " 'model/tf.nn.relu_16/Relu'\n",
      " 'model/quant_conv2d_17/BiasAdd;model/quant_conv2d_20/Conv2D;model/quant_conv2d_17/Conv2D;model/quant_conv2d_17/BiasAdd/ReadVariableOp1'\n",
      " 'model/lambda_9/mul2' 'model/lambda_9/mul4' 'model/lambda_10/sub'\n",
      " 'model/lambda_10/add4' 'model/lambda_10/add5' 'model/lambda_10/mul4'\n",
      " 'model/tf.math.multiply_1/Mul3' 'model/tf.math.multiply_1/Mul4'\n",
      " 'model/tf.math.multiply_1/Mul5' 'model/lambda_11/mul2'\n",
      " 'model/lambda_11/mul3' 'model/lambda_11/mul4' 'model/tf.concat_8/concat'\n",
      " 'model/quant_batch_normalization_17/FusedBatchNormV3;model/quant_conv2d_18/Conv2D'\n",
      " 'model/tf.nn.relu_17/Relu' 'model/lambda_3/resize/ResizeBilinear'\n",
      " 'model/quant_batch_normalization_18/FusedBatchNormV3;model/quant_conv2d_19/Conv2D'\n",
      " 'model/tf.nn.relu_18/Relu'\n",
      " 'model/quant_conv2d_20/BiasAdd;model/quant_conv2d_20/Conv2D;model/quant_conv2d_20/BiasAdd/ReadVariableOp1'\n",
      " 'model/lambda_5/mul2' 'model/lambda_5/mul4' 'model/lambda_6/sub'\n",
      " 'model/lambda_6/add4' 'model/lambda_6/add5' 'model/lambda_6/mul5'\n",
      " 'model/tf.math.multiply/Mul3' 'model/tf.math.multiply/Mul5'\n",
      " 'model/lambda_7/mul3' 'model/lambda_7/mul4' 'model/lambda_7/mul5'\n",
      " 'StatefulPartitionedCall:1']\n"
     ]
    }
   ],
   "source": [
    "threshold=0.0\n",
    "suspected_layers = list(layer_stats[layer_stats['rmse/scale'] > threshold]['tensor_name'])\n",
    "# suspected_layers = list(layer_stats[layer_stats['rmse/scale'] < threshold]['tensor_name'])\n",
    "# suspected_layers = list(layer_stats['tensor_name'])\n",
    "print(f'num of freeze layer {len(suspected_layers)}/{len(layer_stats)}', )\n",
    "print(np.array(suspected_layers))\n",
    "# discrad quant of first few layers would also increase performance\n",
    "# suspected_layers.extend(list(layer_stats[:5]['tensor_name']))\n",
    "# suspected_layers = np.unique(np.array(suspected_layers))\n",
    "# print(suspected_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 22:39:27.117842: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-06-27 22:39:27.117887: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-06-27 22:39:27.118103: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-27 22:39:27.148816: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2022-06-27 22:39:27.148877: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-27 22:39:27.278948: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-06-27 22:39:27.814661: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./checkpoints/day_tw_qat_tf29/save_model_0059_tflite/\n",
      "2022-06-27 22:39:28.018196: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 900094 microseconds.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:40<00:00,  1.22it/s, image=datasets/data_selection/images/image_000741.jpg]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    }
   ],
   "source": [
    "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
    "    denylisted_nodes=suspected_layers)\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "    converter=converter,\n",
    "    debug_dataset=representative_data_gen,\n",
    "    debug_options=debug_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selective model 6017440 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    }
   ],
   "source": [
    "# selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
    "# open('./checkpoints/day_tw_qat_tf29/selective_int8_thresh_29.tflite', 'wb').write(selective_quantized_model)\n",
    "# 39 23596392 \n",
    "# 46 23596960 \n",
    "# 58 23599040 \n",
    "# 65 23598584 \n",
    "# 97 23591704 \n",
    "# rev 38 6017440 \n",
    "selective_quantized_model_dbg = debugger.get_nondebug_quantized_model()\n",
    "num_of_bytes = open(f'./selective_int8_model_rev_{len(suspected_layers)}layer.tflite', 'wb').write(selective_quantized_model_dbg)\n",
    "print(f'selective model {num_of_bytes} bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('WJtf29')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9de21d8ac59078702cddab91338c80379cc39134c659c0396b5010d46774626"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
