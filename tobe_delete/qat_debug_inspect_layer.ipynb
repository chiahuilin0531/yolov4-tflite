{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 16:19:41.258414: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/user/anaconda3/envs/WJtf29/lib/python3.8/site-packages/tensorflow/lite/python/interpreter is not end with tflite_runtime/interpreter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "from tqdm import tqdm\n",
    "FLAGS = edict()\n",
    "\n",
    "# FLAGS.weights ='./checkpoints/day_tw_qat_tf23/save_model_final_tflite/'\n",
    "FLAGS.weights ='./checkpoints/yolov4_tiny/save_model_0000_tflite/'\n",
    "FLAGS.output ='./checkpoints/tmp.tflite'\n",
    "FLAGS.input_size =608\n",
    "FLAGS.quantize_mode ='float32'\n",
    "FLAGS.dataset =\"datasets/data_selection_mix/anno/val_3cls.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "  len_img=10\n",
    "  fimage = open(FLAGS.dataset).readlines()\n",
    "  fimage = [line.split()[0] for line in fimage]\n",
    "  np.random.seed(0)\n",
    "  np.random.shuffle(fimage)\n",
    "  with tqdm(total=len_img, ncols=200) as pbar:\n",
    "    for input_value in range(len_img):\n",
    "      if os.path.exists(fimage[input_value]):\n",
    "        original_image=cv2.imread(fimage[input_value])\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        # Processing V1\n",
    "        # image_data = utils.image_preprocess(np.copy(original_image), [FLAGS.input_size, FLAGS.input_size])\n",
    "        #####################################################################################################\n",
    "        # Processing V2\n",
    "        image_data = cv2.resize(np.copy(original_image), (FLAGS.input_size, FLAGS.input_size))\n",
    "        image_data = image_data / 255.0\n",
    "        #####################################################################################################\n",
    "        img_in = image_data[np.newaxis, ...].astype(np.float32)\n",
    "        pbar.set_postfix({\n",
    "          'image': fimage[input_value]\n",
    "        })\n",
    "        pbar.update(1)\n",
    "        yield [img_in]\n",
    "      else:\n",
    "        pbar.set_postfix({\n",
    "          'image': ''\n",
    "        })\n",
    "        pbar.update(1)\n",
    "\n",
    "def add_statistic(filename):\n",
    "  layer_stats = pd.read_csv(filename)\n",
    "  print(layer_stats.head())\n",
    "  layer_stats['range'] = 255.0 * layer_stats['scale']\n",
    "  layer_stats['rmse/scale'] = layer_stats.apply(\n",
    "      lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
    "  return layer_stats\n",
    "  # layer_stats[['op_name', 'range', 'rmse/scale']].head()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 16:21:49.345332: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-06 16:21:50.217841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7665 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:8c:00.0, compute capability: 7.5\n",
      "2022-07-06 16:21:56.262922: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-07-06 16:21:56.266067: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-07-06 16:21:56.267547: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./checkpoints/yolov4_tiny/save_model_0000_tflite/\n",
      "2022-07-06 16:21:56.312760: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2022-07-06 16:21:56.312823: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: ./checkpoints/yolov4_tiny/save_model_0000_tflite/\n",
      "2022-07-06 16:21:56.416913: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-07-06 16:21:56.457423: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-07-06 16:21:57.090785: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./checkpoints/yolov4_tiny/save_model_0000_tflite/\n",
      "2022-07-06 16:21:57.318924: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1051384 microseconds.\n",
      "2022-07-06 16:21:57.709000: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.20it/s, image=datasets/data_selection/images/image_005680.jpg]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n",
      "  0%|                                                                                                                     | 0/10 [00:00<?, ?it/s, image=datasets/data_selection/images/image_002357.jpg]INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.60s/it, image=datasets/data_selection/images/image_005680.jpg]\n",
      "fully_quantize: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin model 6014016 bytes\n",
      "   op_name  tensor_idx  num_elements    stddev  mean_error  max_abs_error  \\\n",
      "0     RELU         119     2957312.0  0.025487   -0.006334       0.063999   \n",
      "1      PAD         123     2976800.0  0.000000    0.000000       0.000000   \n",
      "2  CONV_2D         127     1478656.0  0.164274    0.001327      41.843178   \n",
      "3     RELU         131     1478656.0  0.033161   -0.000096       0.081139   \n",
      "4  CONV_2D         135     1478656.0  0.145927    0.000984      45.764008   \n",
      "\n",
      "   mean_squared_error     scale  zero_point  \\\n",
      "0            0.000690  0.131196        -128   \n",
      "1            0.000000  0.131196        -128   \n",
      "2            0.027372  0.376181          17   \n",
      "3            0.001100  0.162274        -128   \n",
      "4            0.021484  0.267913          48   \n",
      "\n",
      "                                         tensor_name  \n",
      "0                              model/tf.nn.relu/Relu  \n",
      "1                   model/quant_zero_padding2d_1/Pad  \n",
      "2  model/quant_batch_normalization_1/FusedBatchNo...  \n",
      "3                            model/tf.nn.relu_1/Relu  \n",
      "4  model/quant_batch_normalization_2/FusedBatchNo...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.dirname(FLAGS.output)):\n",
    "  os.makedirs(os.path.dirname(FLAGS.output))\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FLAGS.weights)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.allow_custom_ops = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "  converter=converter, debug_dataset=representative_data_gen)\n",
    "debugger.run()\n",
    "\n",
    "\n",
    "origin_int8_model = debugger.get_nondebug_quantized_model()\n",
    "num_of_bytes = open('./tflite_exp/origin_int8_model.tflite', 'wb').write(origin_int8_model)\n",
    "print(f'origin model {num_of_bytes} bytes')\n",
    "\n",
    "RESULTS_FILE = './debugger_results.csv'\n",
    "RESULTS_FILE_V2 = './debugger_results_V2.csv'\n",
    "with open(RESULTS_FILE, 'w') as f:\n",
    "  debugger.layer_statistics_dump(f)\n",
    "layer_stats = add_statistic(RESULTS_FILE)\n",
    "layer_stats.to_csv(RESULTS_FILE_V2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 16:33:58.602510: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-07-06 16:33:58.602565: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-07-06 16:33:58.602955: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./checkpoints/yolov4_tiny/save_model_0000_tflite/\n",
      "2022-07-06 16:33:58.654848: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2022-07-06 16:33:58.654945: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: ./checkpoints/yolov4_tiny/save_model_0000_tflite/\n",
      "2022-07-06 16:33:58.776680: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-07-06 16:33:59.364534: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./checkpoints/yolov4_tiny/save_model_0000_tflite/\n",
      "2022-07-06 16:33:59.618965: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1016012 microseconds.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.20it/s, image=datasets/data_selection/images/image_005680.jpg]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selective model 6023072 bytes. 21 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "# last_k=85\n",
    "st=100\n",
    "end=len(list(layer_stats['tensor_name']))\n",
    "for last_k in range(1):\n",
    "    suspected_layers = list(layer_stats['tensor_name'])[st:end]\n",
    "    debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
    "        denylisted_nodes=suspected_layers)\n",
    "    debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "        converter=converter,\n",
    "        debug_dataset=representative_data_gen,\n",
    "        debug_options=debug_options)\n",
    "\n",
    "    filename = f'./tflite_exp/selective_int8_model_rev_{len(suspected_layers)}layer_st{st}_end{end}.tflite'\n",
    "    selective_quantized_model_dbg = debugger.get_nondebug_quantized_model()\n",
    "    with open(filename, 'wb') as f:\n",
    "        num_of_bytes = f.write(selective_quantized_model_dbg)\n",
    "    f.close()\n",
    "    print(f'selective model {num_of_bytes} bytes. {len(suspected_layers)} layers')\n",
    "    # subprocess.run(['python', 'evaluate_map_v3.py', '--weights', filename, '--framework', 'tflite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('WJtf29')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9de21d8ac59078702cddab91338c80379cc39134c659c0396b5010d46774626"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
